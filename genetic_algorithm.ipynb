{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import null_space, det\n",
    "from tentacles import *\n",
    "import itertools\n",
    "import os\n",
    "from tqdm import tqdm # type: ignore\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import copy\n",
    "from pymoo.core.problem import ElementwiseProblem # type: ignore\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2 # type: ignore\n",
    "from pymoo.optimize import minimize # type: ignore\n",
    "from pymoo.visualization.scatter import Scatter # type: ignore\n",
    "from pymoo.termination import get_termination\n",
    "from pymoo.util.nds.non_dominated_sorting import NonDominatedSorting\n",
    "from pymoo.indicators.hv import HV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "DISCRETIZATION = 8\n",
    "NEW_PERTURB = 50\n",
    "LIMIT = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First dataset creation (for coarse optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m A \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdeg2rad(\u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     thrust, velocity \u001b[38;5;241m=\u001b[39m \u001b[43mNVE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TENTACLES/tentacles.py:195\u001b[0m, in \u001b[0;36mNVE\u001b[0;34m(L, c, f, A, plot)\u001b[0m\n\u001b[1;32m    177\u001b[0m k_i, b_i, d_mid, L_i, I_i \u001b[38;5;241m=\u001b[39m Get_Stiff_Damp(E1, E2, d_base, d_tip, rho_t, L, N, b1, b2, c)\n\u001b[1;32m    179\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk_i\u001b[39m\u001b[38;5;124m'\u001b[39m: k_i,\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb_i\u001b[39m\u001b[38;5;124m'\u001b[39m: b_i,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m: L\n\u001b[1;32m    193\u001b[0m }\n\u001b[0;32m--> 195\u001b[0m sol \u001b[38;5;241m=\u001b[39m \u001b[43msimulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m theta \u001b[38;5;241m=\u001b[39m sol\u001b[38;5;241m.\u001b[39my[:N, :]\n\u001b[1;32m    197\u001b[0m omega \u001b[38;5;241m=\u001b[39m sol\u001b[38;5;241m.\u001b[39my[N:, :]\n",
      "File \u001b[0;32m~/TENTACLES/tentacles.py:124\u001b[0m, in \u001b[0;36msimulation\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    122\u001b[0m t_span \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m    123\u001b[0m t_eval \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m*\u001b[39mt_span, \u001b[38;5;241m600000\u001b[39m)\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msolve_ivp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequations_of_motion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_span\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBDF\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tentacles/lib/python3.10/site-packages/scipy/integrate/_ivp/ivp.py:655\u001b[0m, in \u001b[0;36msolve_ivp\u001b[0;34m(fun, t_span, y0, method, t_eval, dense_output, events, vectorized, args, **options)\u001b[0m\n\u001b[1;32m    653\u001b[0m status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m status \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 655\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m solver\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinished\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    658\u001b[0m         status \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/tentacles/lib/python3.10/site-packages/scipy/integrate/_ivp/base.py:197\u001b[0m, in \u001b[0;36mOdeSolver.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt\n\u001b[0;32m--> 197\u001b[0m     success, message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/tentacles/lib/python3.10/site-packages/scipy/integrate/_ivp/bdf.py:365\u001b[0m, in \u001b[0;36mBDF._step_impl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LU \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    363\u001b[0m     LU \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mI \u001b[38;5;241m-\u001b[39m c \u001b[38;5;241m*\u001b[39m J)\n\u001b[0;32m--> 365\u001b[0m converged, n_iter, y_new, d \u001b[38;5;241m=\u001b[39m \u001b[43msolve_bdf_system\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_predict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve_lu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewton_tol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m converged:\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m current_jac:\n",
      "File \u001b[0;32m~/miniconda3/envs/tentacles/lib/python3.10/site-packages/scipy/integrate/_ivp/bdf.py:43\u001b[0m, in \u001b[0;36msolve_bdf_system\u001b[0;34m(fun, t_new, y_predict, c, psi, LU, solve_lu, scale, tol)\u001b[0m\n\u001b[1;32m     41\u001b[0m converged \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NEWTON_MAXITER):\n\u001b[0;32m---> 43\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39misfinite(f)):\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tentacles/lib/python3.10/site-packages/scipy/integrate/_ivp/base.py:154\u001b[0m, in \u001b[0;36mOdeSolver.__init__.<locals>.fun\u001b[0;34m(t, y)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun\u001b[39m(t, y):\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tentacles/lib/python3.10/site-packages/scipy/integrate/_ivp/base.py:23\u001b[0m, in \u001b[0;36mcheck_arguments.<locals>.fun_wrapped\u001b[0;34m(t, y)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun_wrapped\u001b[39m(t, y):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/tentacles/lib/python3.10/site-packages/scipy/integrate/_ivp/ivp.py:593\u001b[0m, in \u001b[0;36msolve_ivp.<locals>.fun\u001b[0;34m(t, x, fun)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun\u001b[39m(t, x, fun\u001b[38;5;241m=\u001b[39mfun):\n\u001b[0;32m--> 593\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TENTACLES/tentacles.py:96\u001b[0m, in \u001b[0;36mequations_of_motion\u001b[0;34m(t, y, params)\u001b[0m\n\u001b[1;32m     93\u001b[0m omega_diff[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m omega[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m omega_des\n\u001b[1;32m     95\u001b[0m M_elastic_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m k_i \u001b[38;5;241m*\u001b[39m theta_diff \u001b[38;5;241m-\u001b[39m b_i \u001b[38;5;241m*\u001b[39m omega_diff\n\u001b[0;32m---> 96\u001b[0m M_elastic_right \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk_i\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtheta_diff\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb_i\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43momega_diff\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m A_lat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m*\u001b[39m d_mid \u001b[38;5;241m*\u001b[39m L_i\n\u001b[1;32m     99\u001b[0m U_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(omega \u001b[38;5;241m*\u001b[39m L_i \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mcos(theta))\n",
      "File \u001b[0;32m~/miniconda3/envs/tentacles/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:5762\u001b[0m, in \u001b[0;36m_append_dispatcher\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   5757\u001b[0m     new[\u001b[38;5;28mtuple\u001b[39m(slobj2)] \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   5759\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conv\u001b[38;5;241m.\u001b[39mwrap(new, to_scalar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 5762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_append_dispatcher\u001b[39m(arr, values, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   5763\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (arr, values)\n\u001b[1;32m   5766\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_append_dispatcher)\n\u001b[1;32m   5767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mappend\u001b[39m(arr, values, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "L = 0.6\n",
    "c = 0.5\n",
    "f = 1\n",
    "A = np.deg2rad(60)\n",
    "\n",
    "if True:\n",
    "    thrust, velocity = NVE(L, c, f, A, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_and_extend_dataset(points, dataset_path=None):\n",
    "    \"\"\"\n",
    "    Simulates a list of parameter points and optionally appends the results\n",
    "    to an existing dataset.\n",
    "\n",
    "    Args:\n",
    "        points (np.ndarray): array of shape (N, 4) with parameters [L, c, f, A].\n",
    "        dataset_path (str or None): if provided, loads and extends the dataset at this path,\n",
    "                                    otherwise creates a new one.\n",
    "\n",
    "    Returns:\n",
    "        inputs_tensor (torch.Tensor): tensor of shape (N_total, 4).\n",
    "        outputs_tensor (torch.Tensor): tensor of shape (N_total, 2).\n",
    "    \"\"\"\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "\n",
    "    # Run simulations\n",
    "    for L, c, f, A in tqdm(points, desc=\"Simulating NVE points\"):\n",
    "        try:\n",
    "            thrust, velocity = NVE(L, c, f, A, plot=False)\n",
    "            inputs.append([L, c, f, A])\n",
    "            outputs.append([thrust, velocity])\n",
    "        except Exception:\n",
    "            continue  # Skip failed simulation\n",
    "\n",
    "    # Convert to tensors\n",
    "    inputs_tensor = torch.tensor(inputs, dtype=torch.float32)\n",
    "    outputs_tensor = torch.tensor(outputs, dtype=torch.float32)\n",
    "\n",
    "    # Optionally extend existing dataset\n",
    "    if dataset_path and os.path.exists(dataset_path):\n",
    "        existing = torch.load(dataset_path, weights_only=True)\n",
    "        inputs_tensor = torch.cat([existing[\"inputs\"], inputs_tensor], dim=0)\n",
    "        outputs_tensor = torch.cat([existing[\"outputs\"], outputs_tensor], dim=0)\n",
    "\n",
    "    # Save updated dataset\n",
    "    if dataset_path:\n",
    "        torch.save({\"inputs\": inputs_tensor, \"outputs\": outputs_tensor}, dataset_path)\n",
    "        print(f\"\\n Updated dataset saved to {dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretization for initial grid sampling\n",
    "discretization = DISCRETIZATION\n",
    "\n",
    "# Define parameter ranges\n",
    "L_range = np.linspace(0.1, 0.6, discretization)\n",
    "c_range = np.linspace(0.0, 1.0, discretization)\n",
    "f_range = np.linspace(0.01, 3.0, discretization)\n",
    "A_range_deg = np.linspace(5, 135, discretization)\n",
    "A_range_rad = np.deg2rad(A_range_deg)\n",
    "\n",
    "# Generate all parameter combinations\n",
    "param_grid = np.array(list(itertools.product(L_range, c_range, f_range, A_range_rad)))\n",
    "\n",
    "# Run simulations and save dataset\n",
    "if True:\n",
    "    simulate_and_extend_dataset(\n",
    "        points=param_grid,\n",
    "        dataset_path=\"nve_dataset.pt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NVEModel_norm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class NVEModel(nn.Module):\n",
    "    def __init__(self, model, y_min, y_max):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.y_min = nn.Parameter(y_min, requires_grad=False)\n",
    "        self.y_max = nn.Parameter(y_max, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_norm = self.model(x)\n",
    "        return y_norm * (self.y_max - self.y_min) + self.y_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nve_model_from_dataset(dataset_path=\"nve_dataset.pt\"):\n",
    "    \"\"\"\n",
    "    Trains a neural network on the normalized NVE dataset.\n",
    "    Saves the final model if requested. Returns it only if not saving.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): path to the .pt file containing {\"inputs\": X, \"outputs\": y}.\n",
    "        save_model (bool): if True, saves the trained model to disk and returns nothing.\n",
    "\n",
    "    Returns:\n",
    "        model_with_denorm (nn.Module)\n",
    "    \"\"\"\n",
    "    # Load dataset\n",
    "    data = torch.load(dataset_path, weights_only=True)\n",
    "    X = data[\"inputs\"]\n",
    "    y_raw = data[\"outputs\"]\n",
    "\n",
    "    # Normalize outputs\n",
    "    y_min = y_raw.min(dim=0).values\n",
    "    y_max = y_raw.max(dim=0).values\n",
    "    y_norm = (y_raw - y_min) / (y_max - y_min)\n",
    "\n",
    "    # Split into training and validation sets\n",
    "    num_samples = X.shape[0]\n",
    "    split_idx = int(0.9 * num_samples)\n",
    "    X_train, X_val = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_val = y_norm[:split_idx], y_norm[split_idx:]\n",
    "\n",
    "    # Create DataLoaders\n",
    "    dataset_train = TensorDataset(X_train, y_train)\n",
    "    dataset_val = TensorDataset(X_val, y_val)\n",
    "    loader_train = DataLoader(dataset_train, batch_size=64, shuffle=True)\n",
    "    loader_val = DataLoader(dataset_val, batch_size=64, shuffle=False)\n",
    "\n",
    "    model = NVEModel_norm()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    epochs = 300\n",
    "    patience = 20\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    wait = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        loss_epoch = 0\n",
    "        for xb, yb in loader_train:\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_epoch += loss.item() * xb.size(0)\n",
    "        train_losses.append(loss_epoch / len(loader_train.dataset))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            for xb, yb in loader_val:\n",
    "                pred = model(xb)\n",
    "                val_loss += criterion(pred, yb).item() * xb.size(0)\n",
    "        val_loss /= len(loader_val.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch:3d} | Train Loss: {train_losses[-1]:.4f} | Val Loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    model_with_denorm = NVEModel(model, y_min, y_max)\n",
    "\n",
    "    # Plot losses\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Loss (normalized)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    # Save or return\n",
    "    torch.save(model_with_denorm, \"nve_model.pt\")\n",
    "    print(\"Entire model saved to nve_model.pt\")\n",
    "\n",
    "    return model_with_denorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the multi-objective problem\n",
    "class NVEOptimizationProblem(ElementwiseProblem):\n",
    "    def __init__(self, model):\n",
    "        super().__init__(n_var=4, n_obj=2, n_constr=0,\n",
    "                         xl=np.array([0.1, 0.0, 0.01, np.deg2rad(5)]),\n",
    "                         xu=np.array([0.6, 1.0, 3.0, np.deg2rad(135)]))\n",
    "        self.model = model\n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            pred = self.model(x_tensor).squeeze(0).numpy()\n",
    "\n",
    "        # Objectives: we want to maximize both → negate them for minimization\n",
    "        out[\"F\"] = - pred  # [thrust, velocity]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active learning for model refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_around_pareto(pareto_points, N_new, sigma, bounds, max_attempts=50):\n",
    "    \"\"\"\n",
    "    Sample points around Pareto front with Gaussian noise, ensuring all samples stay within bounds.\n",
    "    If sampling fails after `max_attempts`, the original point is used.\n",
    "    \"\"\"\n",
    "    lower, upper = np.array(bounds[0]), np.array(bounds[1])\n",
    "    M = len(pareto_points)\n",
    "    n_per_point = max(1, N_new // M)\n",
    "    samples = []\n",
    "\n",
    "    for x in pareto_points:\n",
    "        count = 0\n",
    "        while count < n_per_point:\n",
    "            for attempt in range(max_attempts):\n",
    "                noise = np.random.normal(0, sigma, size=(1, 4))\n",
    "                perturbed = x + noise\n",
    "                if np.all(perturbed >= lower) and np.all(perturbed <= upper):\n",
    "                    samples.append(perturbed[0])\n",
    "                    break\n",
    "            else:\n",
    "                # After max_attempts, use the original point\n",
    "                samples.append(x)\n",
    "            count = count + 1\n",
    "\n",
    "    return np.array(samples)[:N_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_pareto_refinement(max_iter=200, N_new=NEW_PERTURB, sigma=0.10, dataset_path=\"nve_dataset.pt\", pop_size=100, delta_threshold=LIMIT):\n",
    "    bounds = (\n",
    "        np.array([0.1, 0.0, 0.01, np.deg2rad(5)]),  # lower\n",
    "        np.array([0.6, 1.0, 3.0, np.deg2rad(135)])  # upper\n",
    "    )\n",
    "\n",
    "\n",
    "    hv = HV(ref_point=np.array([0.0, 0.0]))  # reference\n",
    "    prev_hv = None\n",
    "    delta_hv_history = []\n",
    "\n",
    "    final_pareto_X = None\n",
    "    final_pareto_F = None\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        print(f\"\\n=== Iteration {i+1} ===\")\n",
    "\n",
    "        # Train model on current dataset\n",
    "        model = train_nve_model_from_dataset(dataset_path)\n",
    "\n",
    "        # Optimize current model with NSGA-II\n",
    "        problem = NVEOptimizationProblem(model)\n",
    "        algorithm = NSGA2(pop_size=pop_size)\n",
    "        res = minimize(problem,\n",
    "                       algorithm,\n",
    "                       termination=get_termination(\"moo\"),\n",
    "                       seed=1,\n",
    "                       save_history=False,\n",
    "                       verbose=True)\n",
    "\n",
    "        # Extract Pareto front\n",
    "        pareto_X = res.X\n",
    "        pareto_F = -res.F  # un-negate to get actual thrust and velocity\n",
    "\n",
    "        # Compute hypervolume\n",
    "        hv_now = hv(res.F)\n",
    "        print(f\"Hypervolume: {hv_now}\")\n",
    "        if prev_hv is not None:\n",
    "            delta_hv = np.abs(hv_now - prev_hv)\n",
    "            delta_hv_history.append(delta_hv)\n",
    "            print(f\"Hypervolume delta: {delta_hv:.6f}\")\n",
    "\n",
    "            # Check plateau over last 5 iterations\n",
    "            if len(delta_hv_history) >= 5:\n",
    "                recent_max = np.max(delta_hv_history[-5:])\n",
    "                print(f\"Recent max delta HV: {recent_max:.6f}\")\n",
    "                if recent_max < delta_threshold:\n",
    "                    print(\"Plateau detected — stopping iterations.\")\n",
    "                    break\n",
    "        prev_hv = hv_now\n",
    "\n",
    "        # Plot current Pareto front\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        plt.scatter(\n",
    "        pareto_F[:, 0] * 1000,\n",
    "        pareto_F[:, 1] * 100,\n",
    "        s=50,\n",
    "        facecolors='none',\n",
    "        edgecolors='#e2001a',\n",
    "        linewidths=1.5,\n",
    "        alpha=0.8\n",
    "        )\n",
    "        plt.xlabel(\"Thrust [mN]\", fontsize=12)\n",
    "        plt.ylabel(\"Velocity [cm/s]\", fontsize=12)\n",
    "        plt.title(f\"Pareto Front - Iteration {i+1}\", fontsize=13)\n",
    "        plt.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Store final Pareto front\n",
    "        final_pareto_X = pareto_X\n",
    "        final_pareto_F = pareto_F\n",
    "\n",
    "        # Sample new points around Pareto front\n",
    "        new_points = sample_around_pareto(pareto_X, N_new=N_new, sigma=sigma, bounds=bounds)\n",
    "\n",
    "        # Simulate and update dataset\n",
    "        simulate_and_extend_dataset(new_points, dataset_path=dataset_path)\n",
    "\n",
    "    \n",
    "    # Plot delta HV history\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, len(delta_hv_history) + 1), delta_hv_history, marker='o')\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Delta Hypervolume\")\n",
    "    plt.title(\"Hypervolume Delta Across Iterations\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Return final Pareto front\n",
    "    return final_pareto_X, final_pareto_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application of Pareto front\n",
    "X_pareto, F_pareto = iterative_pareto_refinement(\n",
    "    sigma=np.array([0.2, 0.2, 0.4, np.deg2rad(10)])\n",
    ")\n",
    "# Save final Pareto front\n",
    "np.savez(\"pareto_results.npz\", X=X_pareto, F=F_pareto)\n",
    "print(\"Saved final Pareto front to pareto_results.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical analysis of Pareto front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained neural network model\n",
    "model = torch.load(\"nve_model.pt\")\n",
    "model.eval()\n",
    "\n",
    "# Define the multi-objective optimization problem for NSGA-II\n",
    "class NVEOptimizationProblem(ElementwiseProblem):\n",
    "    def __init__(self, model):\n",
    "        super().__init__(\n",
    "            n_var=4,  # [L, c, f, A]\n",
    "            n_obj=2,  # [thrust, velocity]\n",
    "            n_constr=0,\n",
    "            xl=np.array([0.1, 0.0, 0.01, np.deg2rad(5)]),     # lower bounds\n",
    "            xu=np.array([0.6, 1.0, 3.0, np.deg2rad(135)])    # upper bounds\n",
    "        )\n",
    "        self.model = model\n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        # Evaluate the model for input x\n",
    "        x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.model(x_tensor).squeeze().numpy()\n",
    "        thrust, velocity = y_pred\n",
    "        out[\"F\"] = [-thrust, -velocity]  # negate to maximize\n",
    "\n",
    "# Instantiate the problem and optimizer\n",
    "problem = NVEOptimizationProblem(model)\n",
    "algorithm = NSGA2(pop_size=100)\n",
    "termination = get_termination(\"n_gen\", 100)\n",
    "\n",
    "# Run NSGA-II optimization\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               termination=termination,\n",
    "               seed=1,\n",
    "               save_history=False,\n",
    "               verbose=True)\n",
    "\n",
    "# Extract Pareto front and denegate objectives\n",
    "pareto_X = res.X\n",
    "pareto_F = -res.F\n",
    "thrust = pareto_F[:, 0]\n",
    "velocity = pareto_F[:, 1]\n",
    "power = thrust * velocity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "def analyze_pareto_front(F_pareto, X_pareto, model):\n",
    "    thrusts = F_pareto[:, 0]\n",
    "    velocities = F_pareto[:, 1]\n",
    "    powers = thrusts * velocities\n",
    "\n",
    "    # Max indices\n",
    "    idx_thrust = thrusts.argmax()\n",
    "    idx_velocity = velocities.argmax()\n",
    "    idx_power = powers.argmax()\n",
    "\n",
    "    print(\"=== Best by THRUST ===\")\n",
    "    L, c, f, A = X_pareto[idx_thrust]\n",
    "    print(f\"L={L:.3f} m, c={c:.3f}, f={f:.3f} Hz, A={np.rad2deg(A):.1f}° → \"\n",
    "          f\"Thrust={thrusts[idx_thrust]:.4f} N, Velocity={velocities[idx_thrust]:.4f} m/s, \"\n",
    "          f\"Power={powers[idx_thrust]:.4f} W\")\n",
    "\n",
    "    print(\"\\n=== Best by VELOCITY ===\")\n",
    "    L, c, f, A = X_pareto[idx_velocity]\n",
    "    print(f\"L={L:.3f} m, c={c:.3f}, f={f:.3f} Hz, A={np.rad2deg(A):.1f}° → \"\n",
    "          f\"Thrust={thrusts[idx_velocity]:.4f} N, Velocity={velocities[idx_velocity]:.4f} m/s, \"\n",
    "          f\"Power={powers[idx_velocity]:.4f} W\")\n",
    "\n",
    "    print(\"\\n=== Best by POWER (Thrust·Velocity) ===\")\n",
    "    L, c, f, A = X_pareto[idx_power]\n",
    "    print(f\"L={L:.3f} m, c={c:.3f}, f={f:.3f} Hz, A={np.rad2deg(A):.1f}° → \"\n",
    "          f\"Thrust={thrusts[idx_power]:.4f} N, Velocity={velocities[idx_power]:.4f} m/s, \"\n",
    "          f\"Power={powers[idx_power]:.4f} W\")\n",
    "\n",
    "    # Stats\n",
    "    units = [\"N\", \"m/s\", \"W\"]\n",
    "    for name, arr, unit in zip([\"Thrust\", \"Velocity\", \"Power\"], [thrusts, velocities, powers], units):\n",
    "        print(f\"\\n{name} stats: min={arr.min():.4f} {unit}, max={arr.max():.4f} {unit}, \"\n",
    "              f\"mean={arr.mean():.4f} {unit}, std={arr.std():.4f} {unit}, median={np.median(arr):.4f} {unit}\")\n",
    "\n",
    "    # Pareto scatter\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sc = plt.scatter(thrusts, velocities, c=powers, cmap=\"viridis\", edgecolors='k', s=60)\n",
    "    plt.xlabel(\"Thrust [N]\")\n",
    "    plt.ylabel(\"Velocity [m/s]\")\n",
    "    plt.title(\"Pareto Front Colored by Power\")\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label(\"Power [W]\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Parametric scatter (experimental data)\n",
    "    param_names = [\"L [m]\", \"c\", \"f [Hz]\", \"A [deg]\"]\n",
    "    param_data = [X_pareto[:, 0], X_pareto[:, 1], X_pareto[:, 2], np.rad2deg(X_pareto[:, 3])]\n",
    "\n",
    "    for name, values in zip(param_names, param_data):\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(10, 4), sharex=True)\n",
    "        axs[0].scatter(values, thrusts, color=\"#1f77b4\", edgecolors='k', s=40)\n",
    "        axs[0].set_ylabel(\"Thrust [N]\")\n",
    "        axs[0].set_xlabel(name)\n",
    "        axs[0].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "        axs[1].scatter(values, velocities, color=\"#ff7f0e\", edgecolors='k', s=40)\n",
    "        axs[1].set_ylabel(\"Velocity [m/s]\")\n",
    "        axs[1].set_xlabel(name)\n",
    "        axs[1].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "        if name.startswith(\"f\"):\n",
    "            for ax in axs:\n",
    "                ax.xaxis.set_major_formatter(ScalarFormatter(useMathText=False))\n",
    "                ax.xaxis.get_major_formatter().set_scientific(False)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # NN parametric sweeps — 12 plot grouped in 3 rows (4 subplots each)\n",
    "    DISCRETIZATION = 100\n",
    "    L_range = np.linspace(0.1, 0.6, DISCRETIZATION)\n",
    "    c_range = np.linspace(0.0, 1.0, DISCRETIZATION)\n",
    "    f_range = np.linspace(0.01, 3.0, DISCRETIZATION)\n",
    "    A_range_deg = np.linspace(5, 135, DISCRETIZATION)\n",
    "    A_range_rad = np.deg2rad(A_range_deg)\n",
    "\n",
    "    param_ranges = [L_range, c_range, f_range, A_range_rad]\n",
    "    param_labels_plot = [\"L [m]\", \"c [-]\", \"f [Hz]\", \"A [deg]\"]\n",
    "    output_idx = {\"THRUST\": 0, \"VELOCITY\": 1, \"POWER\": -1}\n",
    "    metric_labels = {\"THRUST\": \"Thrust [N]\", \"VELOCITY\": \"Velocity [m/s]\", \"POWER\": \"Power [W]\"}\n",
    "    param_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "\n",
    "    best_configs = {\n",
    "        \"THRUST\": X_pareto[idx_thrust].tolist(),\n",
    "        \"VELOCITY\": X_pareto[idx_velocity].tolist(),\n",
    "        \"POWER\": X_pareto[idx_power].tolist(),\n",
    "    }\n",
    "\n",
    "    for key in [\"THRUST\", \"VELOCITY\", \"POWER\"]:\n",
    "        fixed_values = best_configs[key]\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(16, 3.5), sharey=False)\n",
    "\n",
    "        for i in range(4):\n",
    "            x_vals = []\n",
    "            for val in param_ranges[i]:\n",
    "                x = fixed_values.copy()\n",
    "                x[i] = val\n",
    "                x_vals.append(x)\n",
    "\n",
    "            X_tensor = torch.tensor(x_vals, dtype=torch.float32)\n",
    "            with torch.no_grad():\n",
    "                y_pred = model(X_tensor).numpy()\n",
    "\n",
    "            if output_idx[key] == -1:\n",
    "                y_out = y_pred[:, 0] * y_pred[:, 1]\n",
    "                y_label = \"Power [W]\"\n",
    "            else:\n",
    "                y_out = y_pred[:, output_idx[key]]\n",
    "                y_label = metric_labels[key]\n",
    "\n",
    "            x_plot = np.rad2deg(param_ranges[i]) if i == 3 else param_ranges[i]\n",
    "            x_fixed = np.rad2deg(fixed_values[i]) if i == 3 else fixed_values[i]\n",
    "            x_label = param_labels_plot[i]\n",
    "\n",
    "            axs[i].plot(x_plot, y_out, color=param_colors[i])\n",
    "            axs[i].axvline(x_fixed, color='r', linestyle='--', linewidth=1)\n",
    "            axs[i].grid(True, linestyle='--', alpha=0.6)\n",
    "            axs[i].set_xlabel(x_label)\n",
    "            if param_labels_plot[i] == \"f [Hz]\":\n",
    "                axs[i].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "            if i == 0:\n",
    "                axs[i].set_ylabel(y_label)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained neural network model\n",
    "model = torch.load(\"nve_model.pt\")\n",
    "model.eval()\n",
    "\n",
    "# Analyze the Pareto front\n",
    "analyze_pareto_front(pareto_F, pareto_X, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tentacles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
