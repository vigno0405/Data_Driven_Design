{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import null_space, det\n",
    "from tentacles import *\n",
    "import itertools\n",
    "import os\n",
    "from tqdm import tqdm # type: ignore\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import copy\n",
    "from pymoo.core.problem import ElementwiseProblem # type: ignore\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2 # type: ignore\n",
    "from pymoo.optimize import minimize # type: ignore\n",
    "from pymoo.visualization.scatter import Scatter # type: ignore\n",
    "from pymoo.termination import get_termination\n",
    "from pymoo.util.nds.non_dominated_sorting import NonDominatedSorting\n",
    "from pymoo.indicators.hv import HV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "DISCRETIZATION = 8\n",
    "NEW_PERTURB = 50\n",
    "LIMIT = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First dataset creation (for coarse optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 0.5\n",
    "c = 0.5\n",
    "f = 3\n",
    "A = np.deg2rad(45)\n",
    "\n",
    "if True:\n",
    "    thrust, velocity = NVE(L, c, f, A, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_and_extend_dataset(points, dataset_path=None):\n",
    "    \"\"\"\n",
    "    Simulates a list of parameter points and optionally appends the results\n",
    "    to an existing dataset.\n",
    "\n",
    "    Args:\n",
    "        points (np.ndarray): array of shape (N, 4) with parameters [L, c, f, A].\n",
    "        dataset_path (str or None): if provided, loads and extends the dataset at this path,\n",
    "                                    otherwise creates a new one.\n",
    "\n",
    "    Returns:\n",
    "        inputs_tensor (torch.Tensor): tensor of shape (N_total, 4).\n",
    "        outputs_tensor (torch.Tensor): tensor of shape (N_total, 2).\n",
    "    \"\"\"\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "\n",
    "    # Run simulations\n",
    "    for L, c, f, A in tqdm(points, desc=\"Simulating NVE points\"):\n",
    "        try:\n",
    "            thrust, velocity = NVE(L, c, f, A, plot=False)\n",
    "            inputs.append([L, c, f, A])\n",
    "            outputs.append([thrust, velocity])\n",
    "        except Exception:\n",
    "            continue  # Skip failed simulation\n",
    "\n",
    "    # Convert to tensors\n",
    "    inputs_tensor = torch.tensor(inputs, dtype=torch.float32)\n",
    "    outputs_tensor = torch.tensor(outputs, dtype=torch.float32)\n",
    "\n",
    "    # Optionally extend existing dataset\n",
    "    if dataset_path and os.path.exists(dataset_path):\n",
    "        existing = torch.load(dataset_path, weights_only=True)\n",
    "        inputs_tensor = torch.cat([existing[\"inputs\"], inputs_tensor], dim=0)\n",
    "        outputs_tensor = torch.cat([existing[\"outputs\"], outputs_tensor], dim=0)\n",
    "\n",
    "    # Save updated dataset\n",
    "    if dataset_path:\n",
    "        torch.save({\"inputs\": inputs_tensor, \"outputs\": outputs_tensor}, dataset_path)\n",
    "        print(f\"\\n Updated dataset saved to {dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretization for initial grid sampling\n",
    "discretization = DISCRETIZATION\n",
    "\n",
    "# Define parameter ranges\n",
    "L_range = np.linspace(0.1, 1, discretization)\n",
    "c_range = np.linspace(0.0, 1.0, discretization)\n",
    "f_range = np.linspace(0.05, 10.0, discretization)\n",
    "A_range_deg = np.linspace(5, 135, discretization)\n",
    "A_range_rad = np.deg2rad(A_range_deg)\n",
    "\n",
    "# Generate all parameter combinations\n",
    "param_grid = np.array(list(itertools.product(L_range, c_range, f_range, A_range_rad)))\n",
    "\n",
    "# Run simulations and save dataset\n",
    "if True:\n",
    "    simulate_and_extend_dataset(\n",
    "        points=param_grid,\n",
    "        dataset_path=\"nve_dataset.pt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NVEModel_norm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class NVEModel(nn.Module):\n",
    "    def __init__(self, model, y_min, y_max):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.y_min = nn.Parameter(y_min, requires_grad=False)\n",
    "        self.y_max = nn.Parameter(y_max, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_norm = self.model(x)\n",
    "        return y_norm * (self.y_max - self.y_min) + self.y_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nve_model_from_dataset(dataset_path=\"nve_dataset.pt\"):\n",
    "    \"\"\"\n",
    "    Trains a neural network on the normalized NVE dataset.\n",
    "    Saves the final model if requested. Returns it only if not saving.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): path to the .pt file containing {\"inputs\": X, \"outputs\": y}.\n",
    "        save_model (bool): if True, saves the trained model to disk and returns nothing.\n",
    "\n",
    "    Returns:\n",
    "        model_with_denorm (nn.Module)\n",
    "    \"\"\"\n",
    "    # Load dataset\n",
    "    data = torch.load(dataset_path, weights_only=True)\n",
    "    X = data[\"inputs\"]\n",
    "    y_raw = data[\"outputs\"]\n",
    "\n",
    "    # Normalize outputs\n",
    "    y_min = y_raw.min(dim=0).values\n",
    "    y_max = y_raw.max(dim=0).values\n",
    "    y_norm = (y_raw - y_min) / (y_max - y_min)\n",
    "\n",
    "    # Split into training and validation sets\n",
    "    num_samples = X.shape[0]\n",
    "    split_idx = int(0.9 * num_samples)\n",
    "    X_train, X_val = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_val = y_norm[:split_idx], y_norm[split_idx:]\n",
    "\n",
    "    # Create DataLoaders\n",
    "    dataset_train = TensorDataset(X_train, y_train)\n",
    "    dataset_val = TensorDataset(X_val, y_val)\n",
    "    loader_train = DataLoader(dataset_train, batch_size=64, shuffle=True)\n",
    "    loader_val = DataLoader(dataset_val, batch_size=64, shuffle=False)\n",
    "\n",
    "    model = NVEModel_norm()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    epochs = 300\n",
    "    patience = 20\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    wait = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        loss_epoch = 0\n",
    "        for xb, yb in loader_train:\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_epoch += loss.item() * xb.size(0)\n",
    "        train_losses.append(loss_epoch / len(loader_train.dataset))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            for xb, yb in loader_val:\n",
    "                pred = model(xb)\n",
    "                val_loss += criterion(pred, yb).item() * xb.size(0)\n",
    "        val_loss /= len(loader_val.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch:3d} | Train Loss: {train_losses[-1]:.4f} | Val Loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    model_with_denorm = NVEModel(model, y_min, y_max)\n",
    "\n",
    "    # Plot losses\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Loss (normalized)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    # Save or return\n",
    "    torch.save(model_with_denorm, \"nve_model.pt\")\n",
    "    print(\"Entire model saved to nve_model.pt\")\n",
    "\n",
    "    return model_with_denorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the multi-objective problem\n",
    "class NVEOptimizationProblem(ElementwiseProblem):\n",
    "    def __init__(self, model):\n",
    "        super().__init__(n_var=4, n_obj=2, n_constr=0,\n",
    "                         xl=np.array([0.1, 0.0, 0.05, np.deg2rad(5)]),\n",
    "                         xu=np.array([1, 1.0, 10.0, np.deg2rad(135)]))\n",
    "        self.model = model\n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            pred = self.model(x_tensor).squeeze(0).numpy()\n",
    "\n",
    "        # Objectives: we want to maximize both → negate them for minimization\n",
    "        out[\"F\"] = - pred  # [thrust, velocity]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active learning for model refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_around_pareto(pareto_points, N_new, sigma, bounds, max_attempts=50):\n",
    "    \"\"\"\n",
    "    Sample points around Pareto front with Gaussian noise, ensuring all samples stay within bounds.\n",
    "    If sampling fails after `max_attempts`, the original point is used.\n",
    "    \"\"\"\n",
    "    lower, upper = np.array(bounds[0]), np.array(bounds[1])\n",
    "    M = len(pareto_points)\n",
    "    n_per_point = max(1, N_new // M)\n",
    "    samples = []\n",
    "\n",
    "    for x in pareto_points:\n",
    "        count = 0\n",
    "        while count < n_per_point:\n",
    "            for attempt in range(max_attempts):\n",
    "                noise = np.random.normal(0, sigma, size=(1, 4))\n",
    "                perturbed = x + noise\n",
    "                if np.all(perturbed >= lower) and np.all(perturbed <= upper):\n",
    "                    samples.append(perturbed[0])\n",
    "                    break\n",
    "            else:\n",
    "                # After max_attempts, use the original point\n",
    "                samples.append(x)\n",
    "            count = count + 1\n",
    "\n",
    "    return np.array(samples)[:N_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_pareto_refinement(max_iter=200, N_new=NEW_PERTURB, sigma=0.10, dataset_path=\"nve_dataset.pt\", pop_size=100, delta_threshold=LIMIT):\n",
    "    bounds = (\n",
    "        np.array([0.1, 0.0, 0.05, np.deg2rad(5)]),  # lower\n",
    "        np.array([1, 1.0, 10.0, np.deg2rad(135)])  # upper\n",
    "    )\n",
    "\n",
    "\n",
    "    hv = HV(ref_point=np.array([0.0, 0.0]))  # reference\n",
    "    prev_hv = None\n",
    "    delta_hv_history = []\n",
    "\n",
    "    final_pareto_X = None\n",
    "    final_pareto_F = None\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        print(f\"\\n=== Iteration {i+1} ===\")\n",
    "\n",
    "        # Train model on current dataset\n",
    "        model = train_nve_model_from_dataset(dataset_path)\n",
    "\n",
    "        # Optimize current model with NSGA-II\n",
    "        problem = NVEOptimizationProblem(model)\n",
    "        algorithm = NSGA2(pop_size=pop_size)\n",
    "        res = minimize(problem,\n",
    "                       algorithm,\n",
    "                       termination=get_termination(\"moo\"),\n",
    "                       seed=1,\n",
    "                       save_history=False,\n",
    "                       verbose=True)\n",
    "\n",
    "        # Extract Pareto front\n",
    "        pareto_X = res.X\n",
    "        pareto_F = -res.F  # un-negate to get actual thrust and velocity\n",
    "\n",
    "        # Compute hypervolume\n",
    "        hv_now = hv(res.F)\n",
    "        print(f\"Hypervolume: {hv_now}\")\n",
    "        if prev_hv is not None:\n",
    "            delta_hv = np.abs(hv_now - prev_hv)\n",
    "            delta_hv_history.append(delta_hv)\n",
    "            print(f\"Hypervolume delta: {delta_hv:.6f}\")\n",
    "\n",
    "            # Check plateau over last 5 iterations\n",
    "            if len(delta_hv_history) >= 5:\n",
    "                recent_max = np.max(delta_hv_history[-5:])\n",
    "                print(f\"Recent max delta HV: {recent_max:.6f}\")\n",
    "                if recent_max < delta_threshold:\n",
    "                    print(\"Plateau detected — stopping iterations.\")\n",
    "                    break\n",
    "        prev_hv = hv_now\n",
    "\n",
    "        # Plot current Pareto front\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        plt.scatter(\n",
    "        pareto_F[:, 0] * 1000,\n",
    "        pareto_F[:, 1] * 100,\n",
    "        s=50,\n",
    "        facecolors='none',\n",
    "        edgecolors='#e2001a',\n",
    "        linewidths=1.5,\n",
    "        alpha=0.8\n",
    "        )\n",
    "        plt.xlabel(\"Thrust [mN]\", fontsize=12)\n",
    "        plt.ylabel(\"Velocity [cm/s]\", fontsize=12)\n",
    "        plt.title(f\"Pareto Front - Iteration {i+1}\", fontsize=13)\n",
    "        plt.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Store final Pareto front\n",
    "        final_pareto_X = pareto_X\n",
    "        final_pareto_F = pareto_F\n",
    "\n",
    "        # Sample new points around Pareto front\n",
    "        new_points = sample_around_pareto(pareto_X, N_new=N_new, sigma=sigma, bounds=bounds)\n",
    "\n",
    "        # Simulate and update dataset\n",
    "        simulate_and_extend_dataset(new_points, dataset_path=dataset_path)\n",
    "\n",
    "    \n",
    "    # Plot delta HV history\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, len(delta_hv_history) + 1), delta_hv_history, marker='o')\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Delta Hypervolume\")\n",
    "    plt.title(\"Hypervolume Delta Across Iterations\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Return final Pareto front\n",
    "    return final_pareto_X, final_pareto_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application of Pareto front\n",
    "X_pareto, F_pareto = iterative_pareto_refinement(\n",
    "    sigma=np.array([0.2, 0.2, 0.4, np.deg2rad(10)])\n",
    ")\n",
    "# Save final Pareto front\n",
    "np.savez(\"pareto_results.npz\", X=X_pareto, F=F_pareto)\n",
    "print(\"Saved final Pareto front to pareto_results.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical analysis of Pareto front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def analyze_pareto_front(F_pareto, X_pareto):\n",
    "    # Compute derived quantities\n",
    "    thrusts = F_pareto[:, 0]\n",
    "    velocities = F_pareto[:, 1]\n",
    "    powers = thrusts * velocities\n",
    "\n",
    "    # Maximum indices\n",
    "    idx_thrust = thrusts.argmax()\n",
    "    idx_velocity = velocities.argmax()\n",
    "    idx_power = powers.argmax()\n",
    "\n",
    "    print(\"=== Best by THRUST ===\")\n",
    "    L, c, f, A = X_pareto[idx_thrust]\n",
    "    print(f\"L={L:.3f} m, c={c:.3f}, f={f:.3f} Hz, A={np.rad2deg(A):.1f}° → Thrust={thrusts[idx_thrust]:.4f} N, Velocity={velocities[idx_thrust]:.4f} m/s\")\n",
    "\n",
    "    print(\"\\n=== Best by VELOCITY ===\")\n",
    "    L, c, f, A = X_pareto[idx_velocity]\n",
    "    print(f\"L={L:.3f} m, c={c:.3f}, f={f:.3f} Hz, A={np.rad2deg(A):.1f}° → Thrust={thrusts[idx_velocity]:.4f} N, Velocity={velocities[idx_velocity]:.4f} m/s\")\n",
    "\n",
    "    print(\"\\n=== Best by POWER (Thrust·Velocity) ===\")\n",
    "    L, c, f, A = X_pareto[idx_power]\n",
    "    print(f\"L={L:.3f} m, c={c:.3f}, f={f:.3f} Hz, A={np.rad2deg(A):.1f}° → Thrust={thrusts[idx_power]:.4f} N, Velocity={velocities[idx_power]:.4f} m/s, Power={powers[idx_power]:.4f} W\")\n",
    "\n",
    "    # Summary statistics with units\n",
    "    units = [\"N\", \"m/s\", \"W\"]\n",
    "    for name, arr, unit in zip([\"Thrust\", \"Velocity\", \"Power\"], [thrusts, velocities, powers], units):\n",
    "        print(f\"\\n{name} stats: min={arr.min():.4f} {unit}, max={arr.max():.4f} {unit}, \"\n",
    "              f\"mean={arr.mean():.4f} {unit}, std={arr.std():.4f} {unit}, median={np.median(arr):.4f} {unit}\")\n",
    "\n",
    "    # Boxplots\n",
    "    colors = [\"#6baed6\", \"#74c476\", \"#fd8d3c\"]\n",
    "    for data, name, color in zip([thrusts, velocities, powers], [\"Thrust [N]\", \"Velocity [m/s]\", \"Power [W]\"], colors):\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.boxplot(y=data, color=color)\n",
    "        plt.ylabel(name, fontsize=12)\n",
    "        plt.title(f\"Distribution of {name}\", fontsize=14)\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Histograms\n",
    "    for data, name, color in zip([thrusts, velocities, powers], [\"Thrust [N]\", \"Velocity [m/s]\", \"Power [W]\"], colors):\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.hist(data, bins=20, color=color, edgecolor='black', alpha=0.8)\n",
    "        plt.xlabel(name)\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.title(f\"Histogram of {name}\")\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Scatter with color-coded power\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sc = plt.scatter(thrusts, velocities, c=powers, cmap=\"viridis\", edgecolors='k', s=60)\n",
    "    plt.xlabel(\"Thrust [N]\", fontsize=12)\n",
    "    plt.ylabel(\"Velocity [m/s]\", fontsize=12)\n",
    "    plt.title(\"Pareto Front with Power Levels\", fontsize=14)\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label(\"Power [W]\", fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Parametric plots: Thrust and Velocity vs each input\n",
    "    param_names = [\"L [m]\", \"c\", \"f [Hz]\", \"A [deg]\"]\n",
    "    param_data = [X_pareto[:, 0], X_pareto[:, 1], X_pareto[:, 2], np.rad2deg(X_pareto[:, 3])]\n",
    "\n",
    "    for name, values in zip(param_names, param_data):\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(10, 4), sharex=True)\n",
    "        axs[0].scatter(values, thrusts, color=\"#1f77b4\", edgecolors='k', s=40)\n",
    "        axs[0].set_ylabel(\"Thrust [N]\")\n",
    "        axs[0].set_xlabel(name)\n",
    "        axs[0].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "        axs[1].scatter(values, velocities, color=\"#ff7f0e\", edgecolors='k', s=40)\n",
    "        axs[1].set_ylabel(\"Velocity [m/s]\")\n",
    "        axs[1].set_xlabel(name)\n",
    "        axs[1].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "        fig.suptitle(f\"Effect of {name} on Thrust and Velocity\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"pareto_results.npz\")\n",
    "X_pareto = data[\"X\"]\n",
    "F_pareto = data[\"F\"]\n",
    "\n",
    "analyze_pareto_front(F_pareto, X_pareto)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soft_robot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
